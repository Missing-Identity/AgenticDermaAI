# ── Ollama ────────────────────────────────────────────────────────────────────
# When running via Docker Compose, use the service name "ollama" as the host.
# For local development, use http://localhost:11434
OLLAMA_BASE_URL=http://ollama:11434

# ── NCBI / PubMed ─────────────────────────────────────────────────────────────
# Get a free API key at https://www.ncbi.nlm.nih.gov/account/
# Without it, PubMed limits you to 3 requests/second (still usable for dev)
NCBI_API_KEY=your_ncbi_api_key_here

# NCBI requires an email for Entrez queries — it is never shared publicly
NCBI_EMAIL=your_email_here

# ── ElevenLabs (Text-to-Speech) ───────────────────────────────────────────────
# Get your key at https://elevenlabs.io
ELEVEN_API_KEY=your_elevenlabs_api_key_here

# ── Model configuration ───────────────────────────────────────────────────────
# Formatter model used by the schema adapter layer
FORMATTER_MODEL=qwen2.5:7b-instruct

# ── Storage (RunPod network volume) ───────────────────────────────────────────
# On RunPod: set this to /root/.ollama so models stored on the network volume
# are used directly (survives pod restarts, no re-downloading).
# Leave commented out for local development — Docker named volume is used instead.
# OLLAMA_MODELS_PATH=/root/.ollama
